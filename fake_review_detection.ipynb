{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"weak on current scienc after see twice i agre much posit five star review out respect read review i 'll repeat everyth i like present i found goofi over ear hairdo facial hair arrang daniel vitali describ `` wild food expert '' distract ugh ditto david wolf extrem goofi wild hairdo on hand jon gabriel describ `` author weight loss expert '' nice groom good present hi stori person transform fellow pound whew becom jock normal weight inspir christian northrup preserv rank one america 's cutest doctor a realli nice look woman present dr. mercola jason vale kri carr alejandro junger fine it disappoint jami oliv popular uk give babi cow growth fluid pas unscientif popular idea milk none present anyth zilch say work doctor t. colin campbel milk bodi bad it good see present take stand sugar they agre evil sugar refin carbohydr with respect dr. northrup `` it 's fat make fat 's sugar '' statement pas muster commun expert recogn evil sugar not mutual exclus recogn proven danger fat particularli fat dead anim extract fat all kind oliv oil not health food data-hook= '' product-link-link '' class= '' a-link-norm '' href= '' /the-china-study-the-most-comprehensive-study-of-nutrition-ever-conducted-and-the-startling-implications-for-diet-weight-loss-and-long-term-health/dp/1932100660/ref=cm_cr_arp_d_rvw_txt ie=utf8 '' the china studi the most comprehens studi nutrit ever conduct and startl implic diet weight loss and long-term health /a data-hook= '' product-link-link '' class= '' a-link-norm '' href= '' /forks-over-knives/dp/b0053zhzi2/ref=cm_cr_arp_d_rvw_txt ie=utf8 '' fork over knive /a data-hook= '' product-link-link '' class= '' a-link-norm '' href= '' /prevent-and-reverse-heart-disease-the-revolutionary-scientifically-proven-nutrition-based-cure/dp/1583333002/ref=cm_cr_arp_d_rvw_txt ie=utf8 '' prevent revers heart diseas the revolutionari scientif proven nutrition-bas cure /a data-hook= '' product-link-link '' class= '' a-link-norm '' href= '' /the-plant-based-journey-a-step-by-step-guide-for-transitioning-to-a-healthy-lifestyle-and-achieving-your-ideal-weight/dp/1941631363/ref=cm_cr_arp_d_rvw_txt ie=utf8 '' the plant-bas journey a step-by-step guid transit healthi lifestyl achiev your ideal weight /a\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv(\"dataset.csv\") \n",
    "\n",
    "dataframe.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "\n",
    "dataframe.dropna(inplace=True) \n",
    "\n",
    "dataframe['length'] = dataframe['text_'].apply(len) \n",
    "\n",
    "dataframe[dataframe['label']=='OR'][['text_','length']].sort_values(by='length',ascending=False).head().iloc[0].text_ \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertmyTxt(rv): \n",
    "    np = [c for c in rv if c not in string.punctuation] \n",
    "    np = ''.join(np) \n",
    "    return [w for w in np.split() if w.lower() not in stopwords.words('english')] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model:  84.81%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataframe['text_'],dataframe['label'],test_size=0.25)\n",
    "# Random Forest Classifier model \n",
    "pip = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=convertmyTxt)),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    ('classifier',RandomForestClassifier())\n",
    "]) \n",
    "\n",
    "pip.fit(x_train,y_train) \n",
    "\n",
    "randomForestClassifier = pip.predict(x_test) \n",
    "randomForestClassifier\n",
    "\n",
    "print('Accuracy of the model: ',str(np.round(accuracy_score(y_test,randomForestClassifier)*100,2)) + '%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the model: 88.83%\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Classifier model\n",
    "pip = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=convertmyTxt)),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    ('classifier',SVC())\n",
    "])\n",
    "\n",
    "pip.fit(x_train,y_train)\n",
    "\n",
    "supportVectorClassifier = pip.predict(x_test)\n",
    "supportVectorClassifier\n",
    "\n",
    "print('accuracy of the model:',str(np.round(accuracy_score(y_test,supportVectorClassifier)*100,2)) + '%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the model: 87.01%\n"
     ]
    }
   ],
   "source": [
    "pip = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=convertmyTxt)),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    ('classifier',LogisticRegression())\n",
    "])\n",
    "\n",
    "pip.fit(x_train,y_train)\n",
    "\n",
    "\n",
    "logisticRegression = pip.predict(x_test)\n",
    "logisticRegression\n",
    "\n",
    "print('accuracy of the model:',str(np.round(accuracy_score(y_test,logisticRegression)*100,2)) + '%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(pip,open('model.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "loaded_model = pickle.load(open('model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fake_news_det(news):\n",
    "    input_data = [news]\n",
    "    prediction = loaded_model.predict(input_data)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['OR'], dtype=object)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_news_det(\"accur descript work great came time m ha\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
